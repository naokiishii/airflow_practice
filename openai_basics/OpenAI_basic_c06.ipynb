{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmXGcJl+BhIBCz2GtjnI4I"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6arkUWfhOCfX",
        "outputId": "b9cc63a9-1d0c-41f0-d689-5c403eefd153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.47.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.47.1-py3-none-any.whl (375 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.47.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import openai\n",
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "IqVjkkl5OQ3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Environment Variables"
      ],
      "metadata": {
        "id": "BwZ91ipzVwJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "client = openai.OpenAI()"
      ],
      "metadata": {
        "id": "RKCF-LR-OS1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic usage\n",
        "davinci model is deprecated and \"gpt-3.5-turbo-instruct\" should be used"
      ],
      "metadata": {
        "id": "gJMqYKO9VzTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"generate me 3 trivia quuestions and answers\"}\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "_Zg3Fp2wTWbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reply.model_dump_json(indent=2))"
      ],
      "metadata": {
        "id": "A3EzD-xEP7pQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d82e1d6a-9bb6-4f6d-dc0d-daff03c4d52c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-AAn68uHlDc8l5gPKU207iNexo7O7o\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"1. Trivia Question: Which planet is known as the \\\"Red Planet\\\"?\\n   Answer: Mars\\n\\n2. Trivia Question: What is the largest mammal in the world?\\n   Answer: The blue whale\\n\\n3. Trivia Question: In Greek mythology, who is the king of the gods?\\n   Answer: Zeus\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": null\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1727135376,\n",
            "  \"model\": \"gpt-3.5-turbo-0125\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": null,\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 67,\n",
            "    \"prompt_tokens\": 17,\n",
            "    \"total_tokens\": 84,\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates English to French.\"},\n",
        "        {\"role\": \"user\", \"content\": 'Translate the following English text to French: I want to eat ramen.'}\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "9whHPfsIbUXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reply.model_dump_json(indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tr-CPLlUAEo",
        "outputId": "19f37f0f-bb41-4a07-dadd-30439e0c1c2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-AAnC3rVwcZnHlaYlLPINF6OmclRSd\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"Je veux manger des ramens.\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": null\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1727135743,\n",
            "  \"model\": \"gpt-3.5-turbo-0125\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": null,\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 9,\n",
            "    \"prompt_tokens\": 37,\n",
            "    \"total_tokens\": 46,\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies the sentiment by either negative, neutral or positive\"},\n",
        "        {\"role\": \"user\", \"content\": 'Classify the following text: I love watching TV.'},\n",
        "        {\"role\": \"assistant\", \"content\": 'Positive'},\n",
        "        {\"role\": \"user\", \"content\": 'Classify the following text: I hate heavy rain.'},\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "dawym0ESVL65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reply.model_dump_json(indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tBR3lX8VgEi",
        "outputId": "8b774eeb-9edc-4571-bd7d-66de9064221d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-AAnJNv3DfLQO9Hxt6gZhQ7RmWUBxY\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"Negative\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": null\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1727136197,\n",
            "  \"model\": \"gpt-3.5-turbo-0125\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": null,\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 1,\n",
            "    \"prompt_tokens\": 59,\n",
            "    \"total_tokens\": 60,\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that creates funny poems.\"},\n",
        "        {\"role\": \"user\", \"content\": 'Generate me a 5 line poem about the topic of. your choosing'}\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_tokens=200,\n",
        ")\n",
        "\n",
        "print(response.model_dump_json(indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t12xBlXdm5dX",
        "outputId": "11a1d0d6-f44a-4344-c451-3b73726f0a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-ABAMZqQuLKlpEQ9aTfk0wOCT5XdVY\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"Sure thing! Here's a 5-line poem about the topic of rainy days:\\n\\nRaindrops tap-dancing on rooftops play,\\nClouds overhead in shades of gray,\\nUmbrellas twirl, puddles abound,\\nNature's symphony, a soothing sound,\\nRainy days wash our worries away.\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": null\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1727224807,\n",
            "  \"model\": \"gpt-3.5-turbo-0125\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": null,\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 62,\n",
            "    \"prompt_tokens\": 35,\n",
            "    \"total_tokens\": 97,\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}